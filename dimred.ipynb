{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 'save' or 'rerun'\n",
    "save_or_rerun = 'save'\n",
    "\n",
    "# 'oil flow' or 'USPS digits'\n",
    "dataset = 'oil flow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = 20\n",
    "hermite_points = 2\n",
    "montecarlo_runs = 10\n",
    "variational_variance = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "experiment_key = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "experiment_folder = Path('results')\n",
    "print('experiment key:', experiment_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:45.107908Z",
     "start_time": "2018-06-19T12:22:44.111212Z"
    },
    "id": "JsGYKpyqdR3G"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sklearn.neighbors\n",
    "import scipy.io as sio\n",
    "import gpflow\n",
    "import IPython.display as ipd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import library.kernels\n",
    "from library.expectations import UnscentedExpectation, AnalyticExpectation, GaussHermiteExpectation, MonteCarloExpectation\n",
    "from library.gplvm import GPLVM\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:45.107908Z",
     "start_time": "2018-06-19T12:22:44.111212Z"
    },
    "id": "rV3EEzJDdR3J"
   },
   "outputs": [],
   "source": [
    "def plot_image_scatter(ax, data, images, image_zoom=1, hide_overlaps=True, color=(1,1,1), previously_drawn_boxes=None):\n",
    "    wh = None\n",
    "    drawn_boxes = previously_drawn_boxes or []\n",
    "    drawn_indices = []\n",
    "    r,g,b = color\n",
    "    \n",
    "    ax.update_datalim(data)\n",
    "    ax.autoscale()\n",
    "    for pos, image in zip(data, images):\n",
    "        image = np.clip(np.dstack([(1-image)*r, (1-image)*g, (1-image)*b, image]),0,1)\n",
    "        img = mpl.offsetbox.AnnotationBbox(\n",
    "            mpl.offsetbox.OffsetImage(image, zoom=image_zoom),\n",
    "            pos, xycoords='data', frameon=False\n",
    "        )\n",
    "        \n",
    "        if wh is not None:\n",
    "            bb = mpl.transforms.Bbox.from_bounds(*(pos-wh/2), *wh)\n",
    "            if hide_overlaps and bb.count_overlaps(drawn_boxes) > 0:\n",
    "                drawn_indices.append(False)\n",
    "                continue\n",
    "        \n",
    "        ax.add_artist(img)\n",
    "        \n",
    "        if wh is None:\n",
    "            ax.figure.canvas.draw()\n",
    "            a = (ax.transData.inverted().transform(img.get_children()[1].get_bbox()))\n",
    "            wh = np.array([a[1,0]-a[0,0], a[1,1]-a[0,1]])\n",
    "            bb = mpl.transforms.Bbox.from_bounds(*(pos-wh/2), *wh)\n",
    "        drawn_boxes.append(bb)\n",
    "        drawn_indices.append(True)\n",
    "    return np.array(drawn_indices), drawn_boxes\n",
    "\n",
    "def kernel_name(k):\n",
    "    if type(k) is gpflow.kernels.Sum:\n",
    "        return '+'.join([kernel_name(k) for k in k.kernels])\n",
    "    if type(k).__name__ == 'MLP':\n",
    "        return f'MLP{k.layers}'\n",
    "    else:\n",
    "        return type(k).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdJ94OI7dR3N"
   },
   "outputs": [],
   "source": [
    "dataset_path_friendly = dataset.replace(' ','_')\n",
    "if save_or_rerun not in ['save','rerun']:\n",
    "    raise Exception(f'Invalid operation {save_or_rerun}')\n",
    "if dataset == 'oil flow':\n",
    "    data = np.load('data/three_phase_oil_flow.npz')\n",
    "    Y = data['Y']\n",
    "    labels = data['labels']\n",
    "elif dataset == 'USPS digits':\n",
    "    data = sio.loadmat('data/usps_all.mat')\n",
    "    N = 500\n",
    "    Y = data['data'][:,0:N,:].T.reshape(-1,256)/256\n",
    "    del data\n",
    "    labels = np.array([x for x in [1,2,3,4,5,6,7,8,9,0] for _ in range(0,N)])\n",
    "    digit_images = np.array([y.reshape(16,16).T for y in Y])\n",
    "else:\n",
    "    raise Exception(f'Unknown Dataset {dataset}')\n",
    "n,D = Y.shape\n",
    "\n",
    "experiment_folder = experiment_folder / dataset_path_friendly / experiment_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5D59HedmdR3P"
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "def set_seed():\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_random_seed(random_seed)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aM0NMQJdR3R"
   },
   "outputs": [],
   "source": [
    "if save_or_rerun in ['save','rerun']:\n",
    "    if dataset == 'oil flow':\n",
    "        analytic_kernel = (lambda: gpflow.kernels.RBF(5, ARD=True), 5)\n",
    "        kernels = [\n",
    "#             analytic_kernel,\n",
    "            (lambda: gpflow.kernels.Matern32(10, ARD=True), 10),\n",
    "        ]\n",
    "    elif dataset == 'USPS digits':\n",
    "        analytic_kernel = (lambda: gpflow.kernels.RBF(5, ARD=True), 5)\n",
    "        kernels = [\n",
    "          analytic_kernel,\n",
    "          (lambda: library.kernels.MLP(5,[30,60]), 5),\n",
    "        ]\n",
    "    else:\n",
    "        raise Exception('Unknown dataset')\n",
    "    \n",
    "    model_descriptions = [\n",
    "        (analytic_kernel, AnalyticExpectation()),\n",
    "        *[(k, UnscentedExpectation()) for k,_ in kernels],\n",
    "        *[(k, GaussHermiteExpectation(hermite_points)) for k,_ in kernels],\n",
    "        *[(k, expt, alpha, montecarlo_runs)\n",
    "            for alpha in [0.01]\n",
    "            for k,Q in kernels\n",
    "            for expt in [MonteCarloExpectation(points) for points in {2*Q,hermite_points**Q,200}]\n",
    "         ],\n",
    "    ]\n",
    "\n",
    "    gplvm_models = {}\n",
    "    for model_description in model_descriptions:\n",
    "        kernel_maker, expectation = model_description[:2]\n",
    "        \n",
    "        if len(model_description) == 2:\n",
    "            alpha, runs = 0, 1\n",
    "        else:\n",
    "            alpha, runs = model_description[2:]\n",
    "        \n",
    "        for run in range(runs):\n",
    "            set_seed()\n",
    "            kernel = kernel_maker()      \n",
    "            Q = kernel.input_dim\n",
    "            X_mean = gpflow.models.PCA_reduce(Y, Q)\n",
    "            set_seed()\n",
    "            Z = np.random.permutation(X_mean.copy())[:m]\n",
    "            with gpflow.defer_build():\n",
    "                model = GPLVM(expectation, X_mean=X_mean, X_var=variational_variance*np.ones((n, Q)), Y=Y, kern=kernel, M=m, Z=Z)\n",
    "                if dataset == 'oil flow':\n",
    "                    model.likelihood.variance = 0.01\n",
    "                elif dataset == 'USPS digits':\n",
    "                    model.likelihood.variance = 0.001\n",
    "                model._name = expectation.__name__.replace('(','-').replace(')','') + '-' + str(run)\n",
    "            model.build()\n",
    "            gplvm_models[(expectation.__name__, kernel_name(kernel), alpha, run)] = model\n",
    "    gplvm_models = pd.Series(gplvm_models)\n",
    "    gplvm_models.index.set_names(['expectation', 'kernel', 'alpha', 'run'], inplace=True)\n",
    "\n",
    "    columns = gplvm_models.index.insert(0, ('analytic','PCA',0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "Uuo1RKa-dR3U",
    "outputId": "ec1cefd0-82b0-4310-f73d-d182ec9d928b"
   },
   "outputs": [],
   "source": [
    "# Fit GPLVMs\n",
    "bar = ipd.ProgressBar(len(gplvm_models))\n",
    "ipd.display(ipd.HTML('<h4>Progress:</h4>'))\n",
    "bar.display()\n",
    "\n",
    "for key, model in gplvm_models.items():\n",
    "    key = dict(zip(gplvm_models.index.names, key))\n",
    "    print(key,'@',datetime.datetime.now().strftime(\"%I:%M %p\"))\n",
    "\n",
    "    if key['run'] == 0:\n",
    "        set_seed()\n",
    "\n",
    "    if key['alpha'] > 0:\n",
    "        opt = gpflow.train.AdamOptimizer(key['alpha'])\n",
    "    else:\n",
    "        opt = gpflow.train.ScipyOptimizer()\n",
    "\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    %time opt.minimize(model, maxiter=5000)\n",
    "    tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "    bar.progress += 1\n",
    "print('Finished @', datetime.datetime.now().strftime(\"%I:%M %p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YYSHxrndR3i"
   },
   "outputs": [],
   "source": [
    "latent_space = pd.DataFrame(\n",
    "    index=range(len(Y)),\n",
    "    columns=pd.MultiIndex.from_tuples(\n",
    "        (\n",
    "            (*column, m, i)\n",
    "            for column in columns\n",
    "            for m in ['mean', 'variance']\n",
    "            for i in range(2) if not (column[1] == 'PCA' and m == 'variance')\n",
    "        ),\n",
    "        names=[*columns.names, 'stat', 'dim']\n",
    "    ),\n",
    "    dtype=float\n",
    ").sort_index(axis=1)\n",
    "\n",
    "latent_space.loc[:, pd.IndexSlice['analytic', 'PCA', 0, 0, 'mean',:]] = gpflow.models.PCA_reduce(Y, 2)\n",
    "\n",
    "for key, model in gplvm_models.items():\n",
    "    kern = model.kern\n",
    "    if isinstance(kern, gpflow.kernels.Stationary):\n",
    "        sensibility = np.sqrt(kern.lengthscales.value)/kern.lengthscales.value\n",
    "        dims = np.argsort(sensibility)[[-1, -2]]\n",
    "        latent_space[(*key, 'mean')] = model.X_mean.value[:, dims]\n",
    "        latent_space[(*key, 'variance')] = model.X_var.value[:, dims]\n",
    "    elif type(kern) is library.kernels.MLP:\n",
    "        assert kern.layers[0] == 2\n",
    "        dims = [0,1]\n",
    "        latent_space[(*key, 'mean')] = model.X_mean.value[:, dims]\n",
    "        latent_space[(*key, 'variance')] = model.X_var.value[:, dims]\n",
    "    else:\n",
    "        raise Exception(f'Unknown kernel: {type(kern)}')\n",
    "\n",
    "if save_or_rerun == 'save':\n",
    "    points_folder = experiment_folder / 'points'\n",
    "    points_folder.mkdir(parents=True)\n",
    "    latent_space.to_hdf(points_folder/f'{dataset_path_friendly}.hdf', key='points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "cfzgUwx9dR3k",
    "outputId": "561ef036-fcc8-4a90-973a-36920fc3cdd8"
   },
   "outputs": [],
   "source": [
    "folds = 5\n",
    "\n",
    "accuracy = pd.DataFrame(\n",
    "    index=pd.RangeIndex(folds, name='fold'),\n",
    "    columns=columns,\n",
    "    dtype=float\n",
    ").sort_index(axis=1)\n",
    "\n",
    "missed = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([range(folds), range(len(Y))], names=['fold', None]),\n",
    "    columns=accuracy.columns,\n",
    "    dtype=bool\n",
    ").sort_index(axis=1)\n",
    "\n",
    "\n",
    "kf = sk.model_selection.KFold(folds, shuffle=True, random_state=random_seed)\n",
    "for i, (trainIdx, testIdx) in enumerate(kf.split(labels)):\n",
    "    y_train, y_test = labels[trainIdx], labels[testIdx]\n",
    "    for column in columns:\n",
    "        knn = sk.neighbors.KNeighborsClassifier(n_neighbors=1, metric='minkowski')\n",
    "        train, test = latent_space.loc[trainIdx,(*column, 'mean')], latent_space.loc[testIdx,(*column, 'mean')]\n",
    "        knn.fit(train, y_train)\n",
    "        predicted_labels = knn.predict(latent_space[(*column, 'mean')])\n",
    "        missed.loc[pd.IndexSlice[i,:],column] = (labels != predicted_labels)\n",
    "        y_pred = knn.predict(test)\n",
    "        accuracy.at[i,column] = sk.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy = accuracy.stack('run')\n",
    "if save_or_rerun == 'save':\n",
    "    tables_folder = experiment_folder / 'tabs'\n",
    "    tables_folder.mkdir(parents=True)\n",
    "    (accuracy.describe().loc[['mean','std']] * 100).T.to_csv(tables_folder/f'acc_{dataset_path_friendly}_mean.csv')\n",
    "    accuracy.to_csv(tables_folder/f'acc_{dataset_path_friendly}.csv')\n",
    "\n",
    "print('Finished @', datetime.datetime.now().strftime(\"%I:%M %p\"))\n",
    "ipd.display((accuracy.describe().loc[['mean','std']] * 100).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPXqMPP7eGxq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key in columns.droplevel(-1).drop_duplicates():\n",
    "    scores = accuracy[key].sort_values()\n",
    "    figname = '_'.join(str(x) for x in key[1:]).replace(' ','')\n",
    "    \n",
    "    best_fold, best_run = accuracy.index[len(scores)//2]\n",
    "    points = latent_space[key][best_run]['mean'].values\n",
    "    misses = missed[key][best_run][best_fold].values\n",
    "\n",
    "    f, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "\n",
    "    if dataset == 'oil flow':\n",
    "        colors = plt.get_cmap('tab10')(range(len(np.unique(labels))))\n",
    "        markers = ['o','X',',']\n",
    "        for j, c in zip(np.unique(labels), colors):\n",
    "            ax.scatter(points[labels==j, 0], points[labels==j, 1], color=c, label=j, marker=markers[j], s=200)\n",
    "            ax.scatter(points[misses, 0], points[misses, 1], facecolors='none', edgecolors='r', linewidths=2, s=450)\n",
    "    elif dataset == 'USPS digits':\n",
    "        drawn_miss, miss_boxes = plot_image_scatter(ax, points[misses],digit_images[misses], color=(255,0,0))\n",
    "        drawn_not, _ = plot_image_scatter(ax, points[~misses],digit_images[~misses], drawn_boxes=miss_boxes)\n",
    "\n",
    "    f.tight_layout()\n",
    "    figs_folder = experiment_folder / 'figs' / key[0]\n",
    "    figs_folder.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(figs_folder/f'{figname}.pdf', bbox_inches='tight', transparent=True)\n",
    "    plt.close(f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "dimred.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
